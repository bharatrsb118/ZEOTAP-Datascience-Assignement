{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation using Clustering Techniques\n",
    "This notebook performs customer segmentation using clustering techniques. We will use both profile information and transaction information to segment the customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load and preprocess the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load and preprocess all datasets\"\"\"\n",
    "    try:\n",
    "        customers = pd.read_csv(\"Customers.csv\")\n",
    "        products = pd.read_csv(\"Products.csv\")\n",
    "        transactions = pd.read_csv(\"Transactions.csv\")\n",
    "        \n",
    "        # Ensure consistent column names\n",
    "        transactions.rename(columns={'customer_id': 'CustomerID', \n",
    "                                  'product_id': 'ProductID'}, inplace=True)\n",
    "        return customers, products, transactions\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "customers, products, transactions = load_data()\n",
    "print(\"Data loaded successfully\")\n",
    "print(\"Transactions shape:\", transactions.shape)\n",
    "print(\"Products shape:\", products.shape)\n",
    "print(\"Customers shape:\", customers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Customer Features\n",
    "Create feature vectors for each customer based on their transaction history and profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_customer_features(customers, transactions, products):\n",
    "    \"\"\"Create feature vectors for each customer\"\"\"\n",
    "    try:\n",
    "        # Create basic purchase statistics\n",
    "        purchase_stats = transactions.groupby('CustomerID').agg({\n",
    "            'TotalValue': ['sum', 'mean', 'count'],\n",
    "            'Quantity': ['sum', 'mean']\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Flatten column names\n",
    "        purchase_stats.columns = ['CustomerID'] + [f'{col[0]}_{col[1]}' for col in purchase_stats.columns[1:]]\n",
    "        \n",
    "        # Create category preferences\n",
    "        product_categories = transactions.merge(products[['ProductID', 'Category']], on='ProductID')\n",
    "        category_pivoted = pd.crosstab(product_categories['CustomerID'], \n",
    "                                     product_categories['Category'],\n",
    "                                     normalize='index')\n",
    "        \n",
    "        # Create recency feature\n",
    "        latest_date = pd.to_datetime(transactions['TransactionDate']).max()\n",
    "        recency = (transactions.groupby('CustomerID')\n",
    "                  .agg({'TransactionDate': lambda x: (latest_date - pd.to_datetime(x).max()).days})\n",
    "                  .rename(columns={'TransactionDate': 'recency'}))\n",
    "        \n",
    "        # Create region features\n",
    "        region_dummies = pd.get_dummies(customers[['CustomerID', 'Region']], \n",
    "                                      prefix='region', \n",
    "                                      columns=['Region'])\n",
    "        \n",
    "        # Merge all features\n",
    "        final_features = (purchase_stats\n",
    "                         .merge(category_pivoted.reset_index(), on='CustomerID', how='left')\n",
    "                         .merge(recency.reset_index(), on='CustomerID', how='left')\n",
    "                         .merge(region_dummies, on='CustomerID', how='left'))\n",
    "        \n",
    "        # Fill missing values\n",
    "        final_features = final_features.fillna(0)\n",
    "        \n",
    "        return final_features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating features: {e}\")\n",
    "        print(\"\\nDebugging info:\")\n",
    "        print(\"Purchase stats columns:\", purchase_stats.columns.tolist())\n",
    "        print(\"Category pivot columns:\", category_pivoted.columns.tolist())\n",
    "        print(\"Region dummy columns:\", region_dummies.columns.tolist())\n",
    "        return None\n",
    "\n",
    "features = create_customer_features(customers, transactions, products)\n",
    "print(\"\\nFeatures created successfully\")\n",
    "print(\"Feature matrix shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Perform clustering and evaluate using Davies-Bouldin Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(features, n_clusters=5):\n",
    "    \"\"\"Perform clustering and evaluate using Davies-Bouldin Index\"\"\"\n",
    "    try:\n",
    "        # Remove CustomerID for clustering\n",
    "        feature_cols = features.columns.difference(['CustomerID'])\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features[feature_cols])\n",
    "        \n",
    "        # Perform KMeans clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        clusters = kmeans.fit_predict(scaled_features)\n",
    "        \n",
    "        # Calculate Davies-Bouldin Index\n",
    "        db_index = davies_bouldin_score(scaled_features, clusters)\n",
    "        \n",
    "        return clusters, db_index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error performing clustering: {e}\")\n",
    "        return None, None\n",
    "\n",
    "clusters, db_index = perform_clustering(features, n_clusters=5)\n",
    "if clusters is not None:\n",
    "    print(f\"\\nClustering performed successfully with DB Index: {db_index:.4f}\")\n",
    "    features['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Clusters\n",
    "Visualize the clusters using relevant plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(features):\n",
    "    \"\"\"Visualize the clusters using relevant plots\"\"\"\n",
    "    try:\n",
    "        # Plot total spend vs. recency\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.scatterplot(x='total_spend_sum', y='recency', hue='Cluster', data=features, palette='viridis')\n",
    "        plt.title('Customer Segments: Total Spend vs. Recency')\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot total transactions vs. average transaction value\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.scatterplot(x='TotalValue_count', y='TotalValue_mean', hue='Cluster', data=features, palette='viridis')\n",
    "        plt.title('Customer Segments: Total Transactions vs. Average Transaction Value')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing clusters: {e}\")\n",
    "\n",
    "visualize_clusters(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "Save the clustering results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(features, output_file):\n",
    "    \"\"\"Save clustering results to CSV\"\"\"\n",
    "    try:\n",
    "        features.to_csv(output_file, index=False)\n",
    "        print(f\"Clustering results saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {e}\")\n",
    "\n",
    "save_results(features, \"Customer_Segments.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
